{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Muhammad Mansoor Alam\n",
        "\n",
        "Task 02: \"Image Generation with Pre-trained Models\"\n",
        "\n",
        "Utilize pre-trained generative models like DALL-E-mini or Stable Diffusion to create images from text prompts."
      ],
      "metadata": {
        "id": "kafNLfbonOBT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How it works?**\n",
        "\n",
        "StableDiffusion is a model that generates images from text prompts. It's based on a concept called \"latent diffusion,\" which involves a few key steps:\n",
        "\n",
        "Super-Resolution Concept: Imagine you have a blurry image, and you train a model to make it clearer. The model doesn't recover lost details magically; it guesses what those details might be based on its training data. This process is called \"super-resolution.\"\n",
        "\n",
        "Denoising Noise: If you take a noisy image (pure random noise) and apply the same idea, the model can \"denoise\" it, gradually turning the noise into a clear image by making educated guesses.\n",
        "\n",
        "Latent Diffusion Model: This idea was expanded in a model called \"latent diffusion,\" which repeatedly refines a noisy image to make it clear and high-resolution.\n",
        "\n",
        "Text-to-Image Generation: To create images from text, you add another step called \"conditioning.\" This involves adding a text representation to the noise and training the model with image-caption pairs.\n",
        "\n",
        "The StableDiffusion architecture consists of three parts:\n",
        "\n",
        "Text Encoder: Converts your text prompt into a vector.\n",
        "Diffusion Model: Denoises a 64x64 image patch repeatedly.\n",
        "Decoder: Converts the final 64x64 image into a high-resolution 512x512 image.\n",
        "Here's the process in simple steps:\n",
        "\n",
        "Text Prompt: Your text is converted into a vector by the text encoder.\n",
        "Denoising: This vector is combined with random noise, and the diffusion model refines this noise over several steps.\n",
        "Rendering: The final refined image patch is upscaled to a high-resolution image by the decoder.\n",
        "Even though the system seems magical, itâ€™s based on lots of training with billions of images and captions. The code for this system is relatively short, showing that complexity comes from the vast amount of data and training, not the code itself."
      ],
      "metadata": {
        "id": "9FOtLcdn1wE3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imports and Downloads**"
      ],
      "metadata": {
        "id": "kbRwbwqSctxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet --upgrade diffusers transformers accelerate invisible_watermark mediapy omegaconf\n",
        "!pip install omegaconf\n",
        "use_refiner = False\n",
        "\n",
        "import mediapy as media\n",
        "import random\n",
        "import sys\n",
        "import torch\n",
        "from diffusers import DiffusionPipeline\n"
      ],
      "metadata": {
        "id": "ufD_d64nr08H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing The Model**"
      ],
      "metadata": {
        "id": "AKF4Z-HYYMf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    model,\n",
        "    torch_dtype=torch.float16,\n",
        "    safety_checker=None,\n",
        "    requires_safety_checker=False\n",
        ")"
      ],
      "metadata": {
        "id": "bG2hkmSEvByV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt**\n",
        "\n",
        "**NOTE: Collab will be using CPU to porcess the model, which will take around 35-40 mins to run , for a single 40x40 image.**\n",
        "\n",
        "**For optimal results, Download ipynb file, and then run it with NVIDIA CUDA, if you have a NVIDIA GPU, this will enable you to process upto 50 images at once and with a resolution of 720p, upto 4k! within minutes.**"
      ],
      "metadata": {
        "id": "IZQKThVlmTeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "prompt = \"purple sky\" #@param {type:\"string\"}\n",
        "seed = 9181757 # @param {type:\"slider\", min:0, max:9000000000, step:1}\n",
        "\n",
        "negative_prompt = \"bad-picture-chill-75v, ng_deepnegative_v1_75t, badhandv4, (worst quality:2), (low quality:2), (normal quality:2), (lowres:2), (bad anatomy:2), (bad hands:2), (watermark:2), (mole:1.5), (freckles:1.5)\" #@param {type:\"string\"}\n",
        "\n",
        "width = 40  #@param {type:\"slider\", min:8, max:2048, step:8}\n",
        "height = 40  #@param {type:\"slider\", min:8, max:2048, step:8}\n",
        "\n",
        "width = int(width)\n",
        "height = int(height)\n",
        "\n",
        "images = pipe(\n",
        "    prompt=prompt,\n",
        "    width=width,\n",
        "    height=height,\n",
        "    negative_prompt=negative_prompt,\n",
        "    output_type=\"latent\" if use_refiner else \"pil\",\n",
        "    generator=torch.Generator().manual_seed(seed)\n",
        ").images\n",
        "\n",
        "if use_refiner:\n",
        "  images = refiner(\n",
        "      prompt = prompt,\n",
        "      negative_prompt = negative_prompt,\n",
        "      image = images,\n",
        "      ).images\n",
        "\n",
        "print(f\"Prompt:\\t{prompt}\\nSeed:\\t{seed}\")\n",
        "\n",
        "base_filename = \"output.jpg\"\n",
        "new_filename = base_filename\n",
        "\n",
        "if os.path.exists(base_filename):\n",
        "    index = 1\n",
        "    while True:\n",
        "        new_filename = f\"output_{index}.jpg\"\n",
        "        if not os.path.exists(new_filename):\n",
        "            break\n",
        "        index += 1\n",
        "\n",
        "images[0].save(new_filename)\n",
        "media.show_images(images)\n"
      ],
      "metadata": {
        "id": "AUc4QJfE-uR9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}